{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten, Activation\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "# Be sure it is a jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"IMAGE_NAME_HERE\" # Uploaded image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mpimg.imread(image_path) # Reading in the image as a matrix of values\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_plot(model, img):\n",
    "    img_batch = np.expand_dims(img, axis=0)\n",
    "    conv_img2 = model.predict(img_batch)\n",
    "    conv_img2 = np.squeeze(conv_img2, axis=0)\n",
    "    print(conv_img2.shape)\n",
    "    plt.imshow(conv_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_first_filter(model):\n",
    "    top_layer = model.layers[0]\n",
    "    plt.imshow(top_layer.get_weights()[0][:, :, :, 0].squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nicer_plot(model, img):\n",
    "    img_batch = np.expand_dims(img, axis=0)\n",
    "    conv_img2 = model.predict(img_batch)\n",
    "    conv_img2 = np.squeeze(conv_img2, axis=0)\n",
    "    print(conv_img2.shape[:2])\n",
    "    conv_img2 = conv_img2.reshape(conv_img2.shape[:2])\n",
    "    plt.imshow(conv_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fake model 1\n",
    "model = Sequential() # Going to have sequential layers\n",
    "model.add(Convolution2D(3, # Number of filters\n",
    "                        (5, 5), # Size of the filters\n",
    "                        input_shape = img.shape)) # Initial image size\n",
    "\n",
    "# Visualize the first filter\n",
    "visualize_first_filter(model)\n",
    "\n",
    "#Visualize what the picture looks after applying the filter\n",
    "nicer_plot(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake model 2\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(1, # Number of filters\n",
    "                        (3, 3), # Size of the filters\n",
    "                        input_shape = img.shape)) # Initial image size\n",
    "\n",
    "# Visualize the first filter\n",
    "visualize_first_filter(model)\n",
    "\n",
    "#Visualize what the picture looks after applying the filter\n",
    "nicer_plot(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake model 3\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(1, # Number of filters\n",
    "                        (3, 3), # Size of the filters\n",
    "                        input_shape = img.shape)) # Initial image size\n",
    "model.add(Activation('relu')) # Removes \n",
    "\n",
    "# Visualize the first filter\n",
    "visualize_first_filter(model)\n",
    "\n",
    "#Visualize what the picture looks after applying the filter\n",
    "nicer_plot(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake model 4\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(1, # Number of filters\n",
    "                        (3, 3), # Size of the filters\n",
    "                        input_shape = img.shape)) # Initial image size\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Visualize the first filter\n",
    "visualize_first_filter(model)\n",
    "\n",
    "#Visualize what the picture looks after applying the filter\n",
    "nicer_plot(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here down shamelessly taken from https://www.tensorflow.org/tutorials/image_retraining\n",
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    file = open(label_file, \"r\") \n",
    "    proto_as_ascii_lines = file.readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    input_name = \"file_reader\"\n",
    "    output_name = \"normalized\"\n",
    "    \n",
    "    # Decode the image into an array\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(\n",
    "        file_reader, channels=3, name=\"png_reader\")\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(\n",
    "        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(\n",
    "        file_reader, channels=3, name=\"jpeg_reader\")\n",
    "        \n",
    "    float_caster = tf.cast(image_reader, tf.float32) # Make sure all numbers are floats\n",
    "    dims_expander = tf.expand_dims(float_caster, 0) # Extra dimension for wiggle room\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width]) # resize\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std]) # Ensure number % of 255\n",
    "    sess = tf.Session() # Start a tensorflow session\n",
    "    result = sess.run(normalized) # Get the normalized tensor that tensorflow can read\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already compiled\n",
    "graph = load_graph('output_graph.pb')\n",
    "label_file = load_labels('output_labels.txt')\n",
    "input_layer = \"Placeholder\"\n",
    "output_layer = \"final_result\"\n",
    "\n",
    "# Set image size for model\n",
    "input_height = 299\n",
    "input_width = 299\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "\n",
    "t = read_tensor_from_image_file(\n",
    "  image_path,\n",
    "  input_height=input_height,\n",
    "  input_width=input_width,\n",
    "  input_mean=input_mean,\n",
    "  input_std=input_std)\n",
    "\n",
    "# gather layers to input and receive image\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a session with the graph set as the model.\n",
    "# Get model outputs and use these to compare the model\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "    results = np.squeeze(results)\n",
    "    top_k = results.argsort()[-5:][::-1] # Order of the top classes\n",
    "    labels = label_file\n",
    "    \n",
    "    for i in top_k:\n",
    "        print(labels[i], results[i])      \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_hands_on_tech",
   "language": "python",
   "name": "all_hands_on_tech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
